{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [0.07495069 0.22485207 0.29980276 0.67455621 0.89940828 1.19921105]\n",
      "[[ 1.  3.  4.  9. 12. 16.]]\n",
      "[array([113.32544379, 111.97633136, 111.30177515, 107.92899408,\n",
      "       105.90532544, 103.20710059]), array([150.80078895, 148.40236686, 147.20315582, 141.20710059,\n",
      "       137.60946746, 132.81262327])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 80\u001b[0m\n\u001b[0;32m     74\u001b[0m     f_min \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m x, f_min\n\u001b[1;32m---> 80\u001b[0m steepest_descent(StybliskiTang, grad, [\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m, in \u001b[0;36msteepest_descent\u001b[1;34m(f, grad, x0, alpha, epsilon, max_iterations)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(grad_x) \u001b[39m<\u001b[39m epsilon: \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mprint\u001b[39m(grad_x)\n\u001b[1;32m---> 68\u001b[0m x \u001b[39m=\u001b[39m X[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m alpha \u001b[39m*\u001b[39;49m grad_x\n\u001b[0;32m     69\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m     70\u001b[0m Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mappend(f(x))\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def StybliskiTang(x) -> float:\n",
    "    \"\"\"f, dimension = 0, len(x)\n",
    "\n",
    "    for i in range(dimension):\n",
    "        xi = x[i]\n",
    "        f += xi**4 - 16*xi**2 + 5*xi\"\"\"\n",
    "    \n",
    "    f = 4*x[0] + 6*x[1] + 2\n",
    "\n",
    "    return f\n",
    "\n",
    "def grad(model: Pipeline, X, Y):\n",
    "    \"\"\"\n",
    "    Assuming to work with the Mean Squared Error function for a Linear Regression Model\n",
    "\n",
    "    MSE = 1/n * Sum(y_i + y_hat)^2\n",
    "    \"\"\"\n",
    "\n",
    "    coeff = model.named_steps['linear'].coef_\n",
    "    print(\"The coefficients are\", coeff)\n",
    "    print(model.named_steps['poly'].transform(np.array(X).reshape(1,-1)))\n",
    "    gradient = []\n",
    "    for i in range(len(X)):\n",
    "        pd = 2/len(X)*(Y-np.dot(coeff,X[i]))*X[i]\n",
    "        gradient.append(pd)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def steepest_descent(f, grad, x0, alpha=0.1, epsilon=1e-5, max_iterations=100):\n",
    "    \"\"\"\n",
    "    Steepest Descent algorithm for finding the minimum of a function.\n",
    "    \n",
    "    Parameters:\n",
    "    - f (function): The objective function to be minimized.\n",
    "    - grad (function): The gradient function of the objective function.\n",
    "    - x0 (np.array): The initial guess for the minimum.\n",
    "    - alpha (float): The step size or learning rate for updating the guess.\n",
    "    - epsilon (float): The tolerance level for convergence.\n",
    "    - max_iterations (int): The maximum number of iterations for the algorithm.\n",
    "        \n",
    "    Returns:\n",
    "    - x_min (np.array): The minimum of the function.\n",
    "    - f_min (float): The value of the function at the minimum.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline([('poly',   PolynomialFeatures(degree=2)),\n",
    "                  ('linear', LinearRegression(fit_intercept=False))]) \n",
    "\n",
    "    X = [x0]\n",
    "    Y = [f(X[-1])]\n",
    "    for i in range(max_iterations):\n",
    "        \n",
    "        model = model.fit(X,Y)\n",
    "        grad_x = grad(model,X[-1], Y[-1])\n",
    "        \n",
    "        if np.linalg.norm(grad_x) < epsilon: break\n",
    "        print(grad_x)\n",
    "        x = X[-1] - alpha * grad_x\n",
    "        X = X.append(x)\n",
    "        Y = Y.append(f(x))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    f_min = f(x)\n",
    "    return x, f_min\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "steepest_descent(StybliskiTang, grad, [3,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
